{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2_4yjzakP8s",
    "colab_type": "text"
   },
   "source": [
    "# NOTE: this HOWTO has been replaced by the `tf.Estimator` API\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# HowTo: running `train` & `validation` loops in the same session with `tf-slim`\n",
    "\n",
    "`Validation` loops are used to monitor `training` to identify when models reach a high variance state, e.g. `overfitting`. \n",
    "\n",
    "The purpose of this notebook is to provide an example of how to run a `validation` loop in the same session as a `train` loop using `tf.slim`. We'll also provide an example on how to show `validation` summaries on `tensorboard`.\n",
    "\n",
    "\n",
    "\n",
    "## references:\n",
    "\n",
    "* This example borrows from the [slim walkthough](https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb) notebook  \n",
    "* recipe for [running train/validation/test loops](https://github.com/tensorflow/tensorflow/issues/5987) in the same `tf.slim` session\n",
    "* plot [training and validation losses](https://stackoverflow.com/questions/37146614/tensorboard-plot-training-and-validation-losses-on-the-same-graph)  on the same tensorboard graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ6P8ndskPJq",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "\n",
    "# Simple Example\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gQMK5A4zpVm7",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "HOME = \"/content\"\n",
    "SLIM = \"/content/models/research/slim\"\n",
    "DATA_DIR = \"/tmp/tfrecords\"\n",
    "\n",
    "import os\n",
    "# load repo for TF-Slim image models\n",
    "found = os.path.isdir('/content/models')\n",
    "if not found:\n",
    "  !git clone https://github.com/tensorflow/models.git\n",
    "  !git clone https://github.com/mixuala/colab_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Kvag4TvZoy2S",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, shutil\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from models.research.slim.datasets import dataset_utils\n",
    "from colab_utils import tboard\n",
    "\n",
    "# Main slim library\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy-Nm6-sruSE",
    "colab_type": "text"
   },
   "source": [
    "## Build `tf.slim` training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aQGSBeHUsQoU",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "### \n",
    "### dataset pre-processing and tensorboard methods\n",
    "###\n",
    "def produce_batch(batch_size, noise=0.3):\n",
    "    xs = np.random.random(size=[batch_size, 1]) * 10\n",
    "    ys = np.sin(xs) + 5 + np.random.normal(size=[batch_size, 1], scale=noise)\n",
    "    return [xs.astype(np.float32), ys.astype(np.float32)]\n",
    "\n",
    "def convert_data_to_tensors(x, y):\n",
    "    inputs = tf.constant(x)\n",
    "    inputs.set_shape([None, 1])\n",
    "    \n",
    "    outputs = tf.constant(y)\n",
    "    outputs.set_shape([None, 1])\n",
    "    return inputs, outputs\n",
    "  \n",
    "  \n",
    "\n",
    "def reset_tensorboard(log_dir):\n",
    "  try:\n",
    "    shutil.rmtree(log_dir)\n",
    "  except:\n",
    "    pass\n",
    "  if not tf.gfile.Exists(log_dir):  tf.gfile.MakeDirs(log_dir)  \n",
    "  not_empty = %ls $log_dir\n",
    "  if not not_empty: print(\"TRAIN_DIR={}, ls:{}\".format(log_dir, not_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "z0iO_a9no91B",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "### \n",
    "### net\n",
    "###\n",
    "def regression_model(inputs, is_training=True, scope=\"regression_model\"):\n",
    "    \"\"\"Creates the regression model.\n",
    "\n",
    "    Args:\n",
    "        inputs: A node that yields a `Tensor` of size [batch_size, dimensions].\n",
    "        is_training: Whether or not we're currently training the model.\n",
    "        scope: An optional variable_op scope for the model.\n",
    "\n",
    "    Returns:\n",
    "        predictions: 1-D `Tensor` of shape [batch_size] of responses.\n",
    "        end_points: A dict of end points representing the hidden layers.\n",
    "    \"\"\"\n",
    "    # Make the model, reuse weights for validation batches using reuse=tf.AUTO_REUSE\n",
    "    with slim.arg_scope([slim.fully_connected], reuse=tf.AUTO_REUSE):\n",
    "        end_points = {}\n",
    "        # Set the default weight _regularizer and acvitation for each fully_connected layer.\n",
    "        with slim.arg_scope([slim.fully_connected],\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            weights_regularizer=slim.l2_regularizer(0.01)):\n",
    "\n",
    "            # Creates a fully connected layer from the inputs with 32 hidden units.\n",
    "            net = slim.fully_connected(inputs, 32, scope='fc1')\n",
    "            end_points['fc1'] = net\n",
    "\n",
    "            # Adds a dropout layer to prevent over-fitting.\n",
    "            net = slim.dropout(net, 0.8, is_training=is_training)\n",
    "\n",
    "            # Adds another fully connected layer with 16 hidden units.\n",
    "            net = slim.fully_connected(net, 16, scope='fc2')\n",
    "            end_points['fc2'] = net\n",
    "\n",
    "            # Creates a fully-connected layer with a single hidden unit. Note that the\n",
    "            # layer is made linear by setting activation_fn=None.\n",
    "            predictions = slim.fully_connected(net, 1, activation_fn=None, scope='prediction')\n",
    "            end_points['out'] = predictions\n",
    "\n",
    "    return predictions, end_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvIQZ7ZbxIrT",
    "colab_type": "text"
   },
   "source": [
    "### add `validation` loop to `train_step_fn()`\n",
    "validate on given step interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5uxbPyhPw-v4",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "  \"\"\"\n",
    "  slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "\n",
    "  usage: slim.learning.train( train_op, logdir, \n",
    "                              train_step_fn=train_step_fn,)\n",
    "  \"\"\"\n",
    "  if hasattr(train_step_fn, 'step'):\n",
    "    train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "  else:\n",
    "    train_step_fn.step = global_step.eval(sess)\n",
    "  \n",
    "  # calc training losses\n",
    "  total_loss, should_stop = slim.learning.train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "  \n",
    "  \n",
    "  # validate on interval\n",
    "  if train_step_fn.step % VALIDATION_INTERVAL == 0:\n",
    "    validiate_loss, validation_delta = sess.run([val_loss, summary_validation_delta])\n",
    "    print(\">> global step {}:    train={}   validation={}  delta={}\".format(train_step_fn.step, \n",
    "                        total_loss, validiate_loss, validiate_loss-total_loss))\n",
    "    \n",
    "\n",
    "  return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmQmGn2qMpbk",
    "colab_type": "text"
   },
   "source": [
    "## Using `TFRecords` with `slim.dataset.Dataset`\n",
    "\n",
    "see: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim/python/slim/data/\n",
    "\n",
    "reading data: \n",
    "- https://www.tensorflow.org/api_guides/python/reading_data\n",
    "- https://github.com/kwotsin/transfer_learning_tutorial/blob/master/train_flowers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QEKpkj_sgJs",
    "colab_type": "text"
   },
   "source": [
    "#### get inputs, targets manually from tf.data.TFRecordDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "PkBTDOFiQF-h",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "3b746d2a-8c9b-4940-d588-af0547fcd6f0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.519981070131E12,
     "user_tz": -480.0,
     "elapsed": 724.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "### using TFRecordDataset directly\n",
    "import os\n",
    "# example proto decode\n",
    "def _parse_function(example_proto):\n",
    "  keys_to_features = {'input': tf.FixedLenFeature((), tf.float32),\n",
    "                      'label': tf.FixedLenFeature((), tf.float32)\n",
    "                     }\n",
    "  parsed_features = tf.parse_single_example(example_proto, keys_to_features)\n",
    "  return parsed_features['input'], parsed_features['label']\n",
    "\n",
    "train_sources = [\"{}/{}\".format(DATA_DIR, f) for f in os.listdir(DATA_DIR) if \"train\" in f]\n",
    "train_dataset = tf.data.TFRecordDataset(train_sources)\n",
    "train_dataset = train_dataset.map(_parse_function).repeat().batch(32)\n",
    "\n",
    "print( type(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IJo9O1yrynI",
    "colab_type": "text"
   },
   "source": [
    "### create `TFRecord` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "FG5nM11MMu15",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    },
    "outputId": "bd785d1e-f031-4614-e0b3-2dcab89148ae",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.519981071315E12,
     "user_tz": -480.0,
     "elapsed": 1080.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_0.tfrecord  train_3.tfrecord       validation_2.tfrecord\r\n",
      "train_1.tfrecord  validation_0.tfrecord  validation_3.tfrecord\r\n",
      "train_2.tfrecord  validation_1.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "### create TFRecord files from produce_batch()\n",
    "\n",
    "if not tf.gfile.Exists(DATA_DIR):  tf.gfile.MakeDirs(DATA_DIR)  \n",
    "\n",
    "def np_to_tfrecord(inputs, labels, filename, data_dir):  \n",
    "  \n",
    "  writer = tf.python_io.TFRecordWriter( \"{}/{}.tfrecord\".format(data_dir, filename))\n",
    "  for m in range(len(inputs)):\n",
    "    # Feature contains a map of string for each feature proto objects\n",
    "    # NOTE: for tf.train.FloatList|Int64List value must be a tuple or list!!\n",
    "    feature = {\n",
    "        \"input\": tf.train.Feature(float_list=tf.train.FloatList(value= inputs[m].tolist() )),\n",
    "        \"label\": tf.train.Feature(float_list=tf.train.FloatList(value= labels[m].tolist() )),\n",
    "    }\n",
    "\n",
    "    # Construct the Example proto object\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    # Serialize the example to a string, write records to a tfrecords file\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "  writer.close()\n",
    "\n",
    "  \n",
    "# create \".tfrecord\" files  \n",
    "for i in range(4):  \n",
    "  x, y = produce_batch(320)    # x.shape=[320,1], y.shape=[320,1]\n",
    "  np_to_tfrecord(x, y, \"train_{}\".format(i), DATA_DIR)\n",
    "  x, y = produce_batch(64)    # x.shape=[320,1], y.shape=[320,1]\n",
    "  np_to_tfrecord(x, y, \"validation_{}\".format(i), DATA_DIR)\n",
    "\n",
    "%ls $DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrltnNMwr_TE",
    "colab_type": "text"
   },
   "source": [
    "### read the `TFRecords` using the Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "jVtdowyITXYf",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170.0
    },
    "outputId": "4e762f29-6b71-4939-a7c2-66615453a1a5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.51998107201E12,
     "user_tz": -480.0,
     "elapsed": 671.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tfrecords/train_3.tfrecord\n",
      "/tmp/tfrecords/train_2.tfrecord\n",
      "/tmp/tfrecords/train_0.tfrecord\n",
      "/tmp/tfrecords/train_1.tfrecord\n",
      "/tmp/tfrecords/validation_1.tfrecord\n",
      "/tmp/tfrecords/validation_0.tfrecord\n",
      "/tmp/tfrecords/validation_2.tfrecord\n",
      "/tmp/tfrecords/validation_3.tfrecord\n",
      "<class 'tensorflow.contrib.slim.python.slim.data.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "### using slim.dataset.Dataset\n",
    "import os\n",
    "\n",
    "### helpers\n",
    "def _count_tfrecord_samples(tfrecord_list):\n",
    "  \"\"\"Count the total number of examples in list of tfrecord files\"\"\"\n",
    "  num_samples = 0\n",
    "  for tfrecord_file in tfrecord_list:\n",
    "      print(tfrecord_file)\n",
    "      for record in tf.python_io.tf_record_iterator(tfrecord_file):\n",
    "          num_samples += 1\n",
    "  return num_samples\n",
    "\n",
    "def load_batch_from_slim_dataset(dataset, batch_size=32):\n",
    "  \"\"\"usage:\n",
    "        x_train, y_train = load_batch_from_slim_dataset(train_dataset)\n",
    "        x_validation, y_validation = load_batch_from_slim_dataset(validation_dataset)  \n",
    "  \"\"\"\n",
    "  data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "                  dataset, common_queue_capacity=32,\n",
    "                  common_queue_min=8)\n",
    "  input, label = data_provider.get(['input', 'label'])\n",
    "  \n",
    "  # Batch it up.\n",
    "  inputs, labels = tf.train.batch(\n",
    "        [input, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=1,\n",
    "        capacity=2 * batch_size)\n",
    "\n",
    "  return [inputs, labels]\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### create slim datasets for train/validation\n",
    "keys_to_features = {\n",
    "    'input': tf.FixedLenFeature( [], tf.float32),\n",
    "    'label': tf.FixedLenFeature( [], tf.float32),\n",
    "}\n",
    "\n",
    "items_to_handlers = {\n",
    "    'input': slim.tfexample_decoder.Tensor('input'),\n",
    "    'label': slim.tfexample_decoder.Tensor('label'),\n",
    "}\n",
    "\n",
    "decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "\n",
    "train_sources = [\"{}/{}\".format(DATA_DIR, f) for f in os.listdir(DATA_DIR) if \"train\" in f]\n",
    "# train_sources = \"{}_*.tfrecord\".format(\"train\")\n",
    "train_dataset = slim.dataset.Dataset(\n",
    "                              data_sources=train_sources,    \n",
    "                              reader=tf.TFRecordReader,\n",
    "                              decoder=decoder,\n",
    "                              num_samples=_count_tfrecord_samples(train_sources),\n",
    "                              items_to_descriptions={})\n",
    "\n",
    "\n",
    "validation_sources = [\"{}/{}\".format(DATA_DIR, f) for f in os.listdir(DATA_DIR) if \"validation\" in f]\n",
    "# validation_sources = \"{}_*.tfrecord\".format(\"validation\")\n",
    "validation_dataset = slim.dataset.Dataset(\n",
    "                              data_sources=validation_sources,    \n",
    "                              reader=tf.TFRecordReader,\n",
    "                              decoder=decoder,\n",
    "                              num_samples=_count_tfrecord_samples(validation_sources),\n",
    "                              items_to_descriptions={})\n",
    "\n",
    "print( type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "idDaVJDbYLuP",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYvY5RYNtGRL",
    "colab_type": "text"
   },
   "source": [
    "## Build graph for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "_fDTDgqEswde",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "outputId": "58097793-0abf-4c0d-b907-5d93db07e0b2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.51998106851E12,
     "user_tz": -480.0,
     "elapsed": 3963.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrok installed\n",
      "status: tensorboard=True, ngrok=True\n",
      "tensorboard url= http://a62b9279.ngrok.io\n",
      "ls: cannot access '/tmp/tensorboard/train': No such file or directory\n",
      "/tmp/tensorboard/train\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "### runtime params\n",
    "###\n",
    "LOG_DIR = '/tmp/tensorboard'\n",
    "TRAIN_DIR = LOG_DIR + \"/train\"\n",
    "LOG_INTERVAL = 100\n",
    "VALIDATION_INTERVAL = 500\n",
    "STEPS = 1000\n",
    "tboard.launch_tensorboard(bin_dir=\"/tmp\", log_dir=LOG_DIR)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "!ls $TRAIN_DIR\n",
    "print(TRAIN_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "IhwzhDFttEoh",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2740.0
    },
    "outputId": "33d6cd93-3c2e-45da-f6bd-89ad1c8a66e7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.51998139071E12,
     "user_tz": -480.0,
     "elapsed": 205558.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: Tensor(\"batch:0\", shape=(32,), dtype=float32) targets: Tensor(\"batch:1\", shape=(32,), dtype=float32)\n",
      "\n",
      " >> total_loss= Tensor(\"total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      " >> validation losses= [<tf.Tensor 'mean_squared_error_1/value:0' shape=() dtype=float32>]\n",
      "TRAIN_DIR=/tmp/tensorboard/train, ls:None\n",
      "ngrok installed\n",
      "status: tensorboard=True, ngrok=True\n",
      "tensorboard url= http://a62b9279.ngrok.io\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /tmp/tensorboard/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      ">> global step 0:    train=27.787139892578125   validation=23.375640869140625  delta=-4.4114990234375\n",
      "INFO:tensorflow:global step 100: loss = 1.3815 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 200: loss = 1.0201 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 300: loss = 0.9106 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 400: loss = 0.5333 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 500: loss = 0.4676 (0.019 sec/step)\n",
      ">> global step 500:    train=0.7000164985656738   validation=0.5016736388206482  delta=-0.19834285974502563\n",
      "INFO:tensorflow:Recording summary at step 505.\n",
      "INFO:tensorflow:global step 600: loss = 0.5261 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 700: loss = 0.4892 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 800: loss = 0.4253 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 900: loss = 0.3167 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 1000: loss = 0.5489 (0.018 sec/step)\n",
      ">> global step 1000:    train=0.4882396459579468   validation=0.4575332701206207  delta=-0.03070637583732605\n",
      "INFO:tensorflow:Recording summary at step 1005.\n",
      "INFO:tensorflow:global step 1100: loss = 0.3148 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 1200: loss = 0.5763 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 1300: loss = 0.4693 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 1400: loss = 0.2494 (0.021 sec/step)\n",
      "INFO:tensorflow:global step 1500: loss = 0.3047 (0.017 sec/step)\n",
      ">> global step 1500:    train=0.375588059425354   validation=0.31387966871261597  delta=-0.06170839071273804\n",
      "INFO:tensorflow:Recording summary at step 1517.\n",
      "INFO:tensorflow:global step 1600: loss = 0.3622 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 1700: loss = 0.2715 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 1800: loss = 0.2733 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 1900: loss = 0.3382 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 2000: loss = 0.2976 (0.019 sec/step)\n",
      ">> global step 2000:    train=0.30215585231781006   validation=0.35261255502700806  delta=0.050456702709198\n",
      "INFO:tensorflow:Recording summary at step 2014.\n",
      "INFO:tensorflow:global step 2100: loss = 0.3046 (0.020 sec/step)\n",
      "INFO:tensorflow:global step 2200: loss = 0.3283 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 2300: loss = 0.2977 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 2400: loss = 0.2665 (0.018 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2495.\n",
      "INFO:tensorflow:global step 2500: loss = 0.3518 (0.017 sec/step)\n",
      ">> global step 2500:    train=0.4898098409175873   validation=0.4312060475349426  delta=-0.05860379338264465\n",
      "INFO:tensorflow:global step 2600: loss = 0.3424 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 2700: loss = 0.3006 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 2800: loss = 0.2947 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 2900: loss = 0.2661 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2973.\n",
      "INFO:tensorflow:global step 3000: loss = 0.3853 (0.020 sec/step)\n",
      ">> global step 3000:    train=0.3153653144836426   validation=0.14478221535682678  delta=-0.1705830991268158\n",
      "INFO:tensorflow:global step 3100: loss = 0.3516 (0.019 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 3200: loss = 0.1972 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 3300: loss = 0.2573 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 3400: loss = 0.2848 (0.021 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 3466.\n",
      "INFO:tensorflow:global step 3500: loss = 0.2187 (0.018 sec/step)\n",
      ">> global step 3500:    train=0.25522756576538086   validation=0.17607265710830688  delta=-0.07915490865707397\n",
      "INFO:tensorflow:global step 3600: loss = 0.2358 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 3700: loss = 0.2916 (0.032 sec/step)\n",
      "INFO:tensorflow:global step 3800: loss = 0.2555 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 3900: loss = 0.2501 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 3962.\n",
      "INFO:tensorflow:global step 4000: loss = 0.2296 (0.017 sec/step)\n",
      ">> global step 4000:    train=0.2301236093044281   validation=0.15709303319454193  delta=-0.07303057610988617\n",
      "INFO:tensorflow:global step 4100: loss = 0.2411 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 4200: loss = 0.2886 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 4300: loss = 0.2650 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 4400: loss = 0.2270 (0.018 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 4453.\n",
      "INFO:tensorflow:global step 4500: loss = 0.1831 (0.020 sec/step)\n",
      ">> global step 4500:    train=0.23848974704742432   validation=0.1565527617931366  delta=-0.08193698525428772\n",
      "INFO:tensorflow:global step 4600: loss = 0.2217 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 4700: loss = 0.4205 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 4800: loss = 0.2045 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 4900: loss = 0.2095 (0.020 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 4955.\n",
      "INFO:tensorflow:global step 5000: loss = 0.4020 (0.021 sec/step)\n",
      ">> global step 5000:    train=0.2097986340522766   validation=0.11536135524511337  delta=-0.09443727880716324\n",
      "INFO:tensorflow:global step 5100: loss = 0.3796 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 5200: loss = 0.1684 (0.020 sec/step)\n",
      "INFO:tensorflow:global step 5300: loss = 0.2785 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 5400: loss = 0.2878 (0.018 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 5457.\n",
      "INFO:tensorflow:global step 5500: loss = 0.1690 (0.015 sec/step)\n",
      ">> global step 5500:    train=0.18690527975559235   validation=0.14352130889892578  delta=-0.043383970856666565\n",
      "INFO:tensorflow:global step 5600: loss = 0.2443 (0.016 sec/step)\n",
      "INFO:tensorflow:global step 5700: loss = 0.2277 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 5800: loss = 0.2058 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 5900: loss = 0.1780 (0.019 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 5942.\n",
      "INFO:tensorflow:global step 6000: loss = 0.2381 (0.018 sec/step)\n",
      ">> global step 6000:    train=0.20545054972171783   validation=0.16709595918655396  delta=-0.03835459053516388\n",
      "INFO:tensorflow:global step 6100: loss = 0.2232 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 6200: loss = 0.1878 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 6300: loss = 0.2329 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 6400: loss = 0.2081 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 6448.\n",
      "INFO:tensorflow:global step 6500: loss = 0.1790 (0.017 sec/step)\n",
      ">> global step 6500:    train=0.18303418159484863   validation=0.0917721837759018  delta=-0.09126199781894684\n",
      "INFO:tensorflow:global step 6600: loss = 0.2806 (0.020 sec/step)\n",
      "INFO:tensorflow:global step 6700: loss = 0.1588 (0.014 sec/step)\n",
      "INFO:tensorflow:global step 6800: loss = 0.3451 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 6900: loss = 0.1889 (0.021 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 6949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 7000: loss = 0.2393 (0.016 sec/step)\n",
      ">> global step 7000:    train=0.15158812701702118   validation=0.12626442313194275  delta=-0.02532370388507843\n",
      "INFO:tensorflow:global step 7100: loss = 0.1524 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 7200: loss = 0.1922 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 7300: loss = 0.1835 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 7400: loss = 0.2123 (0.018 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 7459.\n",
      "INFO:tensorflow:global step 7500: loss = 0.2090 (0.015 sec/step)\n",
      ">> global step 7500:    train=0.23725485801696777   validation=0.10145480185747147  delta=-0.1358000636100769\n",
      "INFO:tensorflow:global step 7600: loss = 0.1827 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 7700: loss = 0.2275 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 7800: loss = 0.2638 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 7900: loss = 0.2335 (0.017 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 7970.\n",
      "INFO:tensorflow:global step 8000: loss = 0.2220 (0.018 sec/step)\n",
      ">> global step 8000:    train=0.25551503896713257   validation=0.20415019989013672  delta=-0.05136483907699585\n",
      "INFO:tensorflow:global step 8100: loss = 0.2858 (0.021 sec/step)\n",
      "INFO:tensorflow:global step 8200: loss = 0.1718 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 8300: loss = 0.2308 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 8400: loss = 0.2413 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 8472.\n",
      "INFO:tensorflow:global step 8500: loss = 0.1939 (0.020 sec/step)\n",
      ">> global step 8500:    train=0.22248539328575134   validation=0.1118931919336319  delta=-0.11059220135211945\n",
      "INFO:tensorflow:global step 8600: loss = 0.2190 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 8700: loss = 0.2633 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 8800: loss = 0.1819 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 8900: loss = 0.2249 (0.020 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 8966.\n",
      "INFO:tensorflow:global step 9000: loss = 0.2223 (0.021 sec/step)\n",
      ">> global step 9000:    train=0.23004378378391266   validation=0.12401317805051804  delta=-0.10603060573339462\n",
      "INFO:tensorflow:global step 9100: loss = 0.1702 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 9200: loss = 0.2394 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 9300: loss = 0.2953 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 9400: loss = 0.1663 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 9472.\n",
      "INFO:tensorflow:global step 9500: loss = 0.1979 (0.017 sec/step)\n",
      ">> global step 9500:    train=0.20394068956375122   validation=0.14590531587600708  delta=-0.05803537368774414\n",
      "INFO:tensorflow:global step 9600: loss = 0.1685 (0.017 sec/step)\n",
      "INFO:tensorflow:global step 9700: loss = 0.2476 (0.018 sec/step)\n",
      "INFO:tensorflow:global step 9800: loss = 0.2036 (0.019 sec/step)\n",
      "INFO:tensorflow:global step 9900: loss = 0.1664 (0.016 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 9973.\n",
      "INFO:tensorflow:global step 10000: loss = 0.1461 (0.018 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "Finished training. Last batch loss: 0.1460669\n",
      "Checkpoint saved in /tmp/tensorboard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## graph\n",
    "with tf.Graph().as_default():\n",
    "  \n",
    "  if \"TFRecordDataset\" and False:\n",
    "    ### get inputs, targets manually from tf.data.TFRecordDataset()\n",
    "    batch_size = 32\n",
    "    x_train, y_train = produce_batch(batch_size)\n",
    "    x_validation, y_validation = produce_batch(batch_size)\n",
    "    inputs, targets = convert_data_to_tensors(x_train, y_train)\n",
    "    val_inputs, val_targets = convert_data_to_tensors(x_validation, y_validation)\n",
    "    print(\"inputs/targets:\", inputs,targets)\n",
    "   \n",
    "  else:  \n",
    "    ### get inputs, targets from slim.data.dataset.Dataset()\n",
    "    inputs, targets = load_batch_from_slim_dataset(train_dataset)\n",
    "    print(\"inputs:\", inputs, \"targets:\", targets)\n",
    "    inputs = tf.reshape(inputs, [-1,1])\n",
    "    targets = tf.reshape(targets, [-1,1])\n",
    "#     print(\"inputs:\", inputs, \"targets:\", targets)\n",
    "    \n",
    "    val_inputs, val_targets = load_batch_from_slim_dataset(validation_dataset)\n",
    "    val_inputs = tf.reshape(val_inputs, [-1,1])\n",
    "    val_targets = tf.reshape(val_targets, [-1,1])\n",
    "    \n",
    "    \n",
    "\n",
    "  predictions, nodes = regression_model(inputs, is_training=True)\n",
    "  val_predictions, _ = regression_model(val_inputs, is_training=False)\n",
    "    \n",
    "\n",
    "  ###\n",
    "  ### train graph\n",
    "  ###\n",
    "  # with tf.variable_scope(\"train\"):\n",
    "  loss = tf.losses.mean_squared_error(labels=targets, predictions=predictions)\n",
    "  \n",
    "  ###\n",
    "  ### validation graph\n",
    "  ###     evaluate from `train_step_fn()`, usually after each epoch\n",
    "  ###\n",
    "  # careful, use different loss_collection so you don't add validation losses to training losses\n",
    "  val_loss = tf.losses.mean_squared_error(labels=val_targets, predictions=val_predictions,\n",
    "                                          loss_collection=\"validation\" \n",
    "                                         )\n",
    "                                         \n",
    "  ### train_op\n",
    "  total_loss = tf.losses.get_total_loss()       # excludes loss_collection=\"validation\"\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "  train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "  print(\"\\n >> total_loss=\", total_loss)  \n",
    "  \n",
    "  \n",
    "  ### add summaries\n",
    "  # train summaries\n",
    "  summary_loss = tf.summary.scalar(\"train/loss\", total_loss)\n",
    "  train_writer = tf.summary.FileWriter(TRAIN_DIR)\n",
    "\n",
    "  # validation summaries\n",
    "  summary_validation_loss = tf.summary.scalar(\"validation/loss\", val_loss )\n",
    "  summary_validation_delta = tf.summary.scalar(\"validation/loss_delta\", (val_loss-loss) )                          \n",
    "  print(\"\\n >> validation losses=\", tf.losses.get_losses(loss_collection=\"validation\"))\n",
    "\n",
    "\n",
    "  \n",
    "  if True: reset_tensorboard(TRAIN_DIR)\n",
    "    \n",
    "    \n",
    "  tboard.launch_tensorboard(log_dir=LOG_DIR)\n",
    "\n",
    "  # Run the training inside a session.\n",
    "  final_loss = slim.learning.train(\n",
    "      train_op,\n",
    "      train_step_fn=train_step_fn,\n",
    "      logdir=LOG_DIR,\n",
    "      number_of_steps=STEPS,\n",
    "#       summary_op=train_summary_op,\n",
    "      summary_writer=train_writer,\n",
    "      save_summaries_secs=10,\n",
    "      save_interval_secs=1000,\n",
    "      log_every_n_steps=LOG_INTERVAL,\n",
    "      )\n",
    "  \n",
    "print(\"Finished training. Last batch loss:\", final_loss)\n",
    "print(\"Checkpoint saved in %s\" % LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSmw3ijtC9fj",
    "colab_type": "text"
   },
   "source": [
    "# Flowers example using `TFRecord` datasets\n",
    "uses the flowers dataset from slim models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "uhfASQkoDNMH",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "b66d88b1-59e1-4923-ba2d-1d8341f01383",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.519981398658E12,
     "user_tz": -480.0,
     "elapsed": 726.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/slim\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "wEaA4O3hDjGR",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "5a1660da-5118-4341-ab95-3ef4a69efab7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.519981400086E12,
     "user_tz": -480.0,
     "elapsed": 749.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/slim\n"
     ]
    }
   ],
   "source": [
    "%cd $SLIM\n",
    "from preprocessing import inception_preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "\n",
    "def load_batch(dataset, batch_size=32, height=299, width=299, is_training=False):\n",
    "    \"\"\"Loads a single batch of data.\n",
    "    \n",
    "    Args:\n",
    "      dataset: The dataset to load.\n",
    "      batch_size: The number of images in the batch.\n",
    "      height: The size of each image after preprocessing.\n",
    "      width: The size of each image after preprocessing.\n",
    "      is_training: Whether or not we're currently training or evaluating.\n",
    "    \n",
    "    Returns:\n",
    "      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\n",
    "      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n",
    "      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\n",
    "    \"\"\"\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset, common_queue_capacity=32,\n",
    "        common_queue_min=8)\n",
    "    image_raw, label = data_provider.get(['image', 'label'])\n",
    "    \n",
    "    # Preprocess image for usage by Inception.\n",
    "    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n",
    "    \n",
    "    # Preprocess the image for display purposes.\n",
    "    image_raw = tf.expand_dims(image_raw, 0)\n",
    "    image_raw = tf.image.resize_images(image_raw, [height, width])\n",
    "    image_raw = tf.squeeze(image_raw)\n",
    "\n",
    "    # Batch it up.\n",
    "    images, images_raw, labels = tf.train.batch(\n",
    "          [image, image_raw, label],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=1,\n",
    "          capacity=2 * batch_size)\n",
    "    \n",
    "    return images, images_raw, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "43_I3sJwGALj",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "## runtime params\n",
    "VALIDATION_INTERVAL = 1\n",
    "\n",
    "# colab GPU adjustments\n",
    "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0YmY9TfhFwDB",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "train_step = slim.learning.train_step\n",
    "\n",
    "# slim.learning.train(train_step_fn=)\n",
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "  \"\"\"\n",
    "  slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "  \"\"\"\n",
    "  if hasattr(train_step_fn, 'step'):\n",
    "    train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "  else:\n",
    "    train_step_fn.step = global_step.eval(sess)\n",
    "  \n",
    "  # calc training losses\n",
    "  total_loss, should_stop = train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "  \n",
    "  \n",
    "  # validate on interval\n",
    "  if train_step_fn.step and train_step_fn.step % VALIDATION_INTERVAL == 0:\n",
    "    np_train_loss, np_val_loss, _ = sess.run([train_loss, val_loss, summary_validation_delta])\n",
    "    print(\">> global step {}:    train={}   validation={}  delta={}\".format(train_step_fn.step, \n",
    "                        np_train_loss, np_val_loss, np_val_loss-np_train_loss))\n",
    "    \n",
    "\n",
    "  return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZZr9q1KbDb8u",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "def my_cnn(images, num_classes, is_training):  # is_training is not used...\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected], reuse=tf.AUTO_REUSE):\n",
    "      with slim.arg_scope([slim.max_pool2d], kernel_size=[3, 3], stride=2):\n",
    "          net = slim.conv2d(images, 64, [5, 5], scope=\"conv1\")\n",
    "          net = slim.max_pool2d(net)\n",
    "          net = slim.conv2d(net, 64, [5, 5], scope=\"conv2\")\n",
    "          net = slim.max_pool2d(net)\n",
    "          net = slim.flatten(net)\n",
    "          net = slim.fully_connected(net, 192, scope=\"fc1\")\n",
    "          net = slim.fully_connected(net, num_classes, activation_fn=None, scope=\"fc2\")       \n",
    "          return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxccWeNWLcWM",
    "colab_type": "text"
   },
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "Tx0FkgqPDUMX",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 309.0
    },
    "outputId": "44ddda8a-629f-40bd-d139-6b319e099594",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.519981420543E12,
     "user_tz": -480.0,
     "elapsed": 15092.0,
     "user": {
      "displayName": "michael lin",
      "photoUrl": "//lh3.googleusercontent.com/-etfWG7MvQwk/AAAAAAAAAAI/AAAAAAAAADM/BxW0OLTdkjI/s50-c-k-no/photo.jpg",
      "userId": "111539764795298113840"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save model to /tmp/tensorboard/flowers\n",
      "ngrok installed\n",
      "status: tensorboard=True, ngrok=True\n",
      "tensorboard url= https://a62b9279.ngrok.io\n",
      "inputs: Tensor(\"batch:0\", shape=(32, 299, 299, 3), dtype=float32) targets: Tensor(\"batch:2\", shape=(32,), dtype=int64)\n",
      "TRAIN_DIR=/tmp/tensorboard, ls:None\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /tmp/tensorboard/flowers/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global step 1: loss = 1.5598 (2.252 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "Finished training. Final batch loss 1\n"
     ]
    }
   ],
   "source": [
    "from datasets import flowers\n",
    "\n",
    "# This might take a few minutes.\n",
    "LOG_DIR = '/tmp/tensorboard'\n",
    "TRAIN_DIR = LOG_DIR + \"/flowers\"\n",
    "print('Will save model to %s' % TRAIN_DIR)\n",
    "\n",
    "tboard.launch_tensorboard(bin_dir=\"/tmp\", log_dir=LOG_DIR)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    dataset = flowers.get_split('train', flowers_data_dir)\n",
    "    images, _, labels = load_batch(dataset)\n",
    "    print(\"inputs:\", images, \"targets:\", labels)\n",
    "\n",
    "  \n",
    "    val_dataset = flowers.get_split('validation', flowers_data_dir)\n",
    "    val_images, _, val_labels = load_batch(val_dataset)\n",
    "    \n",
    "    \n",
    "    # Create the model:\n",
    "    logits = my_cnn(images, num_classes=dataset.num_classes, is_training=True)\n",
    "    val_logits = my_cnn(val_images, num_classes=dataset.num_classes, is_training=False)\n",
    " \n",
    "    # Specify the `train` loss function:\n",
    "    one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)\n",
    "    train_loss = tf.losses.softmax_cross_entropy (one_hot_labels, logits)\n",
    "    total_loss = slim.losses.get_total_loss()\n",
    "    \n",
    "    # Specify the `validation` loss function:\n",
    "    val_one_hot_labels = slim.one_hot_encoding(val_labels, dataset.num_classes)\n",
    "    val_loss = tf.losses.softmax_cross_entropy (val_one_hot_labels, val_logits, \n",
    "                                     loss_collection=\"validation\")\n",
    "    \n",
    "\n",
    "    # Create some summaries to visualize the training process:\n",
    "    tf.summary.scalar('train/Total_Loss', total_loss)\n",
    "    tf.summary.scalar('validation/Validation_Loss', val_loss)\n",
    "    summary_validation_delta = tf.summary.scalar('validation/Validation_Delta', (val_loss - train_loss))\n",
    "  \n",
    "    # Specify the optimizer and create the train op:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "    if True: reset_tensorboard(LOG_DIR)\n",
    "        \n",
    "    # Run the training:\n",
    "    final_loss = slim.learning.train(\n",
    "      train_op,\n",
    "      train_step_fn=train_step_fn,\n",
    "      logdir=TRAIN_DIR,\n",
    "      number_of_steps=1, # For speed, we just do 1 epoch\n",
    "      session_config=sess_config,        \n",
    "      save_summaries_secs=1)\n",
    "  \n",
    "    print('Finished training. Final batch loss %d' % final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Fa6Fv5oa4F_K",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HOWTO: tf.slim train+validate.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [],
   "collapsed_sections": [
    "8QEKpkj_sgJs"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
